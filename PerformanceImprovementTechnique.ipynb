{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1301122-6dc3-4289-bb9f-d1997d05264d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJvLITexNRah",
    "outputId": "9661629a-1e21-45a8-b90f-519fd1964180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as tr\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import copy\n",
    "import urllib.request\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a90513-9cc1-4bc6-b767-f3d889647295",
   "metadata": {
    "id": "gr7z0NLXMLgc"
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = \"/content/drive/MyDrive/models/torch_basic_study\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d332d1f-2842-4264-9736-5982ee1d8ea6",
   "metadata": {
    "id": "koo8QSXmq7Hg",
    "tags": []
   },
   "source": [
    "# Performance Improvement Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca07968-4e99-4a0d-9b79-f07f5009075e",
   "metadata": {
    "id": "Js6ceH6vrnKI"
   },
   "source": [
    "## Prevent Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3161ce-205a-4359-8d0e-634c59cadcf9",
   "metadata": {
    "id": "2BZQQaAQrC7I"
   },
   "source": [
    "1. Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1192f30c-3d9e-4ff4-901b-4ecd3804209c",
   "metadata": {
    "id": "aX5iKc74vFLB"
   },
   "source": [
    "2. L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a18f498-7a56-454f-a357-47915436754e",
   "metadata": {
    "id": "MTlEqn6dvG1I"
   },
   "source": [
    "3. Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd699ab0-446e-45a7-8469-ff1a47dae704",
   "metadata": {
    "id": "CLbkdOtovIXI"
   },
   "source": [
    "4. Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596404b5-1a34-4cd9-b006-c12b9227bf57",
   "metadata": {
    "id": "NRDWbNFVrcyw"
   },
   "source": [
    "5. Disturb Label (used when classfication task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89229be7-5273-474a-9b71-baba0105bc36",
   "metadata": {
    "id": "fgvlZkIHrCRp"
   },
   "outputs": [],
   "source": [
    "class DisturbLabel(nn.Module):\n",
    "  def __init__(self, alpha, num_classes):\n",
    "    super(DisturbLabel, self).__init__()\n",
    "    self.alpha = alpha\n",
    "    self.C = num_classes\n",
    "    self.p_c = (1 - ((self.C - 1) / self.C) * (alpha / 100))\n",
    "    self.p_i = (1 - self.p_c) / (self.C - 1)\n",
    "\n",
    "  def forward(self, y):\n",
    "    y_tensor = y.type(torch.LongTensor).view(-1, 1)\n",
    "    depth = self.C\n",
    "    y_one_hot = torch.ones(y_tensor.size()[0], depth) * self.p_i\n",
    "    y_one_hot.scatter_(1, y_tensor, self.p_c)\n",
    "    y_one_hot = y_one_hot.view(*(tuple(y.shape) + (-1,)))\n",
    "    distribution = torch.distributions.OneHotCategorical(y_one_hot)\n",
    "    y_disturbed = distribution.sample()\n",
    "    y_disturbed = y_disturbed.max(dim=1)[1]\n",
    "    return y_disturbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2392d4bc-3ef9-4a6d-8066-aa3f8cb5e6e1",
   "metadata": {
    "id": "P9ja8fOJxlDU"
   },
   "outputs": [],
   "source": [
    "disturblabels = DisturbLabel(alpha=30, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18df5c5-5e87-40aa-8a92-551a2af880d5",
   "metadata": {
    "id": "eP0ayFE8wpNp"
   },
   "outputs": [],
   "source": [
    "for epoch in range(50):\n",
    "  running_loss = 0.0\n",
    "  for data in trainloader:\n",
    "    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    labels = disturblabels(labels).to(device)\n",
    "    loss = criterion(outputs, labels)\n",
    "    # ...... 이하 생략 ......"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023f0a68-2a20-4f37-a266-f2f1bf5da31e",
   "metadata": {
    "id": "hvlc3FX3sf6a"
   },
   "source": [
    "6. Disturb Value (used when regression task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a25a4-0596-479b-9ed8-1354e4ac53ad",
   "metadata": {
    "id": "oyZyATzkspCQ"
   },
   "outputs": [],
   "source": [
    "def noise_generator(x, alpha):\n",
    "  noise = torch.normal(0, 1e-8, size=(len(x), 1))\n",
    "  noise[torch.randint(0, len(x), (int(len(x) * (1 - alpha)),))] = 0\n",
    "  return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1590087-0b22-4afe-80f1-33259b392d2c",
   "metadata": {
    "id": "hp3sYzrnyqfy"
   },
   "outputs": [],
   "source": [
    "for epoch in range(400):\n",
    "  for data in trainloader:\n",
    "    inputs, values = data\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    values = values + noise_generator(values, alpha)\n",
    "    loss =criterion(outputs, values)\n",
    "    # ...... 이하 생략 ......"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221211bc-6013-4c34-ae9a-f198e747793f",
   "metadata": {
    "id": "ouGbOEmVsfvZ"
   },
   "source": [
    "7. Label Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fe5a33-ecce-43d1-8c66-1931ab0f4ed6",
   "metadata": {
    "id": "yu-FhzXo1ChB"
   },
   "source": [
    "\\begin{align}\n",
    "  y_{ls} = (1 - α)y\\hspace{0.2cm}+\\hspace{0.2cm} \\frac{α}{K}\n",
    "  \\\\(K는 클래스 수, α는 스무딩 비율, y는 0 또는 1)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33cb23e-8fa2-41de-b820-e7dcc06d5a8f",
   "metadata": {
    "id": "cbPRXrKEsouZ"
   },
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "  def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "    super(LabelSmoothingLoss, self).__init__()\n",
    "    self.confidence = 1.0 - smoothing\n",
    "    self.smoothing = smoothing\n",
    "    self.cls = classes\n",
    "    self.dim = dim\n",
    "  \n",
    "  def forward(self, pred, target):\n",
    "    pred = pred.log_softmax(dim=self.dim)\n",
    "    with torch.no_grad():\n",
    "      true_dist = torch.zeros_like(pred)\n",
    "      true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "      true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "    return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc6585c-faeb-4486-a4d6-327f47e0c214",
   "metadata": {
    "id": "XBvE0Eno4ZUJ"
   },
   "outputs": [],
   "source": [
    "criterion = LabelSmoothingLoss(classes=10, smoothing=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e7f220-f55c-4c62-be3b-da388abf2ea2",
   "metadata": {
    "id": "V7WrdRHYr4gQ"
   },
   "source": [
    "## Resolved Data Imvalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0773b82-cf3d-4f4c-9332-a2703e85c6d6",
   "metadata": {
    "id": "WKwYUihLbpKm"
   },
   "source": [
    "design for dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd1fe8-528f-4a49-ae99-e9b02e28f427",
   "metadata": {
    "id": "ExhyQyi9sMPp"
   },
   "outputs": [],
   "source": [
    "def make_weights(labels, nclasses):\n",
    "  labels = np.array(labels)\n",
    "  weight_list = []\n",
    "  for cls in range(nclasses):\n",
    "    idx = np.where(labels == cls)[0]\n",
    "    count = len(idx)\n",
    "    weight = 1 / count\n",
    "    weights = [weight] * count\n",
    "    weight_list += weights\n",
    "  return weight_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e0a2c8-4fc4-4f40-85af-661bf4c08f43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423,
     "referenced_widgets": [
      "3e6245c315d649cabbf76b674fc53395",
      "ff1a6027512c40059821780791c118e7",
      "40106be0d75e40b696e321a730ad87bb",
      "52c012a9dfe942abae3e494e184eabc8",
      "b447ce34e3cd43e286d1c153d3ab4f37",
      "5018fac925da48fbb5e6c2b19343b422",
      "fefc698287144d5b8cacaade2cc4715c",
      "9a50c9bf45c143109d952d74657a964e",
      "95c81c11efa44070a0eb7a23c7e7e420",
      "76fa162d11dd4ea3a6121e99ea4fe4a6",
      "6cffd40b8ff74b6293c0a8dd1fe1660d",
      "2b3c974eff9541a1a9c365df4c6b8b6d",
      "10da831475ce4e69909139aa910033e6",
      "0be78a5fe39b428abb0ad3ea7bf739cf",
      "fb86467e3b194cf5a8a2ff8e1c7ca284",
      "9782bd10204547cea6a358de63bbff95",
      "2e4f84d54c9b45b18d05c37b8c1e80e0",
      "1af71dc0893e46d193fdaebc1a94a3e5",
      "cc8a0c54b1e1473fa742d43613d9c701",
      "abce8610652644ae943ffce28a304400",
      "b5f23f56360f4767b174c49caeb2120d",
      "6c45b8eb2f464f07882eb425d3a0c36a",
      "2d8b0d95b46d4fb7b3760ee83845dc13",
      "4ce3f4cde06f4fb1baca9b47b792a1cb",
      "054f298fe5fa47268810bac6614685c4",
      "2f2237a3169e4f74b25f4034e3229e95",
      "9d5a14cfcf994b0d8df8fcee993a56cc",
      "268bc98c62c44abc940f2a60b6467a19",
      "206dfb322e8640a5abecb0efa6c16533",
      "68c817a814a1480584b2cc835ed16a29",
      "c933f8ec2b4945f98864db6abe7d0b54",
      "04d49920275244b9856c8dd1fb332540",
      "a1e47dbc8dde465a834d2316d4547220",
      "e0ba4c380c404ca4a15c3bbbdf3de481",
      "c8689e275e994885abbff331a49e6949",
      "c6c2f7eb1dab40ab98d758596fe59b28",
      "936b82431a604b31b9dffa1c58fa4046",
      "99aa889a87aa46afb94851883064c329",
      "99cc95c42c12483b89cffb3f1ebef4bc",
      "9c746f6fff594f1f8fcdd598d3f6650d",
      "536463f3c34149469639ce4782ee532c",
      "203759fdd8b64ca598d0814bd1ed6fc7",
      "f37cf0d5db8d4ef3bb1d94d8482033fb",
      "bcb27786bd5f4c309b4afd31fedd62c4"
     ]
    },
    "id": "oQkQ1ZqPZUDf",
    "outputId": "b0a36f66-dbe1-4f93-d092-5f0fbd7aeafe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6245c315d649cabbf76b674fc53395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3c974eff9541a1a9c365df4c6b8b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8b0d95b46d4fb7b3760ee83845dc13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ba4c380c404ca4a15c3bbbdf3de481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transf = transforms.Compose([transforms.Resize((16, 16)), transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.FashionMNIST(root=\"./data\", train=True, download=True,  transform=transf)\n",
    "\n",
    "weights = make_weights(trainset.targets, len(trainset.classes))\n",
    "weights = torch.DoubleTensor(weights)\n",
    "\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n",
    "trainloader_wrs = DataLoader(trainset, batch_size=6, sampler=sampler)\n",
    "trainloader_rs = DataLoader(trainset, batch_size=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f65ce2e-a8c4-4d23-ae29-8299ab583331",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fktS9-UvgDuZ",
    "outputId": "a6efb96a-6795-4235-f443-7b9860f7fe79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 0, 4, 3, 3, 4])\n",
      "tensor([5, 2, 9, 4, 4, 2])\n",
      "tensor([2, 6, 4, 6, 7, 3])\n",
      "tensor([5, 1, 7, 3, 2, 5])\n",
      "tensor([6, 8, 6, 3, 5, 1])\n",
      "tensor([4, 8, 6, 6, 2, 0])\n",
      "===============\n",
      "tensor([1, 1, 9, 3, 2, 5])\n",
      "tensor([4, 2, 1, 4, 3, 3])\n",
      "tensor([1, 7, 4, 7, 9, 2])\n",
      "tensor([0, 2, 8, 1, 1, 4])\n",
      "tensor([6, 1, 2, 3, 1, 8])\n",
      "tensor([5, 0, 5, 4, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "for idx, data in enumerate(trainloader_wrs):\n",
    "  print(data[1])\n",
    "  if idx == 5: break\n",
    "print(\"=\"*15)\n",
    "for idx, data in enumerate(trainloader_rs):\n",
    "  print(data[1])\n",
    "  if idx == 5: break\n",
    "\n",
    "# 뭐 대충 비율 알맞게 나온다고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b16a452-d173-4c27-8ced-b9fa2b4e61e1",
   "metadata": {
    "id": "vYUf13cYc7Ih"
   },
   "source": [
    "function of nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876c9d39-a33c-432e-9b20-179560bdbc90",
   "metadata": {
    "id": "83eG7M6pbmf5"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "num_ins = [40, 35, 20, 65, 70, 153, 408, 43, 58, 183, 590] # lenght of each classes\n",
    "weights = [(1 - (x / sum(num_ins)) for x in num_ins)]\n",
    "class_weights = torch.FloatTensor(weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de6ec85-9e3c-4172-ae9d-8a5e67594ef0",
   "metadata": {
    "id": "gLeW94eNdc1w"
   },
   "source": [
    "Confusion Matrix : for result analysis, not for directly resolved data imblance problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e99061f-1d15-4e9e-a5fc-7816e10956a0",
   "metadata": {
    "id": "F9lUDwxeg0R3"
   },
   "source": [
    "대각 성분이 짙으면 예측을 잘한거다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b6daae-d9b8-42ee-9be7-521d3e2f424d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "FwTaCnxYdsyW",
    "outputId": "c5c408cf-8951-4219-ce43-56d79173d47f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "actual = [1,1,1,0,0,0,0,0,2,2,2,2,2,2,2,2]\n",
    "prediction = [1,2,2,0,2,2,1,2,0,1,0,2,2,2,2,2]\n",
    "c_mat = confusion_matrix(actual, prediction)\n",
    "plt.figure(figsize = (8, 6))\n",
    "sns.heatmap(c_mat, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=.5)\n",
    "b, t = plt.ylim()\n",
    "b += .5\n",
    "t -= .5\n",
    "plt.ylim(b, t)\n",
    "plt.savefig(\"/content/confusion_matrix.png\")\n",
    "plt.show()\n",
    "# 예측값이 2에 많이 치우친 것을 알 수 있다. \n",
    "# 이를 통해서 2가 상대적으로 과적합 되었다는 해석을 추가적으로 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce0639e-de2c-4293-b41c-854f1e6ccd97",
   "metadata": {
    "id": "2rA4d3hHr4cI"
   },
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f266c3-59e0-4917-84b1-1c193d9986e5",
   "metadata": {
    "id": "YXuenKtRlukg"
   },
   "source": [
    "Pre-trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3e3fa9-d0c2-4888-9baa-dbd45dc5c47f",
   "metadata": {
    "id": "m3EEgy0msNJI"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "alexnet = models.alexnet().to(device)\n",
    "resnet18 = models.resnet18().to(device)\n",
    "vgg16 = models.vgg16().to(device)\n",
    "densenet = models.densenet161().to(device)\n",
    "inception = models.inception_v3().to(device)\n",
    "googlenet = models.googlenet().to(device)\n",
    "shufflenet = models.shufflenet_v2_x1_0().to(device)\n",
    "mobilenet_v2 = models.mobilenet_v2().to(device)\n",
    "resnext50_32x4d = models.resnext50_32x4d().to(device)\n",
    "wide_resnet50_2 = models.wide_resnet50_2().to(device)\n",
    "mnasnet = models.mnasnet1_0().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb62cc-1ae5-4cf2-8f7c-cd44f91342ec",
   "metadata": {
    "id": "xdoBGvVjkBVH"
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fx = nn.Linear(num_ftrs, 10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6443e81d-933a-4cd2-86d5-d2cc05f110e7",
   "metadata": {
    "id": "zkhVEv3Ulxdw"
   },
   "source": [
    "Model Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdee53e-f7b4-4829-9e55-2e885314c955",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "a830158c5fbe471a80db4ed62fc9620c",
      "8a6fbf34603449778fde8b3f01372036",
      "bd54f87a389640d0ab3f279cd75a6fd4",
      "ebb7988512bb4ff9989b2c8d95473e98",
      "e602dc0befe549e597a1dc7d3f9ef8c5",
      "490254d55bcb484db99d33cd004e0217",
      "76dae2d567954eb7b9b6eb8d3987ee1c",
      "4f74027a16874e6b9b7cca75c04eddab",
      "a8c949376d1a447ca9f567e19f208d52",
      "838e56a35d5c4e8a82ac0dc3b6cdd1d4",
      "41b53d84308b4262a6b9946dedf2d84d"
     ]
    },
    "id": "8SkpXgfWkBTY",
    "outputId": "66fc3964-604d-4abf-f40a-acdec223477f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a830158c5fbe471a80db4ed62fc9620c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/233M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = torchvision.models.alexnet(pretrained=True)\n",
    "num_ftrs = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_ftrs, 10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fe1714-44ce-4de9-9a9b-652dd65c90cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oa9Wq8bQkBQw",
    "outputId": "3627ae66-909e-46c7-a22b-ce52f2ec23ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end!\n"
     ]
    }
   ],
   "source": [
    "# freezing parameters\n",
    "for i, (name, param) in enumerate(model.named_parameters()):\n",
    "  param.requires_grad = False\n",
    "  if i == 9:\n",
    "    print(\"end!\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19b878f-f1ae-4dc7-909b-7235e785eef0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYJcG5qKkBOo",
    "outputId": "d90395e9-2064-4c46-f861-99251900bd73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 classifier.6.bias False\n",
      "0 classifier.6.bias False\n",
      "3 classifier.6.bias False\n",
      "3 classifier.6.bias False\n",
      "6 classifier.6.bias False\n",
      "6 classifier.6.bias False\n",
      "8 classifier.6.bias False\n",
      "8 classifier.6.bias False\n",
      "10 classifier.6.bias False\n",
      "10 classifier.6.bias False\n",
      "1 classifier.6.bias True\n",
      "1 classifier.6.bias True\n",
      "4 classifier.6.bias True\n",
      "4 classifier.6.bias True\n",
      "6 classifier.6.bias True\n",
      "6 classifier.6.bias True\n"
     ]
    }
   ],
   "source": [
    "# check freezing\n",
    "f_list = [0, 3, 6, 8, 10]\n",
    "c_list = [1, 4, 6]\n",
    "\n",
    "for i in f_list:\n",
    "  print(i, name, model.features[i].weight.requires_grad)\n",
    "  print(i, name, model.features[i].bias.requires_grad)\n",
    "\n",
    "for i in c_list:\n",
    "  print(i, name, model.classifier[i].weight.requires_grad)\n",
    "  print(i, name, model.classifier[i].bias.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e45e73f-4431-4529-b9c3-a058e3eaa240",
   "metadata": {
    "id": "F-nuz85yr4VI"
   },
   "source": [
    "## Semi-supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4772f2b-b1cd-4795-93d1-e6cce6be2eec",
   "metadata": {
    "id": "KPVk1U_oors6"
   },
   "source": [
    "Pseudo Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bbfaee-6a00-4d75-aaee-147485d778fa",
   "metadata": {
    "id": "rwOQEmBrsNgu"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cff11a-d475-48b3-b00f-76b47a1dc1b7",
   "metadata": {
    "id": "MeAGBSnupDli"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "  def __init__(self, x_data, y_data, transform=None):\n",
    "    self.x_data = x_data\n",
    "    self.y_data = y_data\n",
    "    self.transform = transform\n",
    "    self.len = len(y_data)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    sample = self.x_data[index], self.y_data[index]\n",
    "    if self.transform:\n",
    "      sample = self.transform(sample)\n",
    "    return sample\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.len\n",
    "\n",
    "class TrainTransform:\n",
    "  def __call__(self, sample):\n",
    "    inputs, labels = sample\n",
    "    transf = transforms.Compose([\n",
    "                                 transforms.ToPILImage(), \n",
    "                                 transforms.RandomHorizontalFlip(), \n",
    "                                 transforms.ToTensor()])\n",
    "    final_output = transf(inputs)\n",
    "    return final_output, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f23e14-d77e-4561-814c-5c2905f277f5",
   "metadata": {
    "id": "CT1p43ODpEbn"
   },
   "outputs": [],
   "source": [
    "def balanced_subset(data, labels, num_cls, num_data):\n",
    "  num_data_per_class = num_data // num_cls\n",
    "  data1 = torch.tensor([], dtype=torch.float)\n",
    "  data2 = torch.tensor([], dtype=torch.float)\n",
    "  labels1 = torch.tensor([], dtype=torch.long)\n",
    "  labels2 = torch.tensor([], dtype=torch.long)\n",
    "  for cls in range(num_cls):\n",
    "    idx = np.where(labels.numpy() == cls)[0]\n",
    "    shuffled_idx = np.random.choice(len(idx), len(idx), replace=False)\n",
    "    data1 = torch.cat([data1, data[shuffled_idx[:num_data_per_class]]], dim=0)\n",
    "    data2 = torch.cat([data2, data[shuffled_idx[num_data_per_class:]]], dim=0)\n",
    "    labels1 = torch.cat([labels1, labels[shuffled_idx[:num_data_per_class]]], dim=0)\n",
    "    labels2 = torch.cat([labels2, labels[shuffled_idx[num_data_per_class:]]], dim=0)\n",
    "  return data1, data2, labels1, labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789ab17-8064-4992-8916-68352f9d3e0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423,
     "referenced_widgets": [
      "c4b0bd172b274a39b291afd1bf5e8fe0",
      "32c96858cdca42deaf0c7625973b6fcc",
      "191c31974a75483a8a43dc231ce2830e",
      "b43fb5b71aa94baf9c3c4a2c83ff7fb9",
      "7677c2b749e34b8bb0c3584f316b670d",
      "e38f33ef275a40d289520f8a2a85ce2b",
      "0ed93dd20f17453ab5c1190011c651a5",
      "d9394e85e6d34a159c24b0f0547b2651",
      "0ffa28bd65104a68a3b73d63334ca970",
      "1a969bf21b9547fea771622d95592b74",
      "670ee93732ed49ac8c7eaf87e474cb9c",
      "6b8b02d1986e4d798d0419db1f1593d2",
      "c2ce12927db84441813188b65f2942bf",
      "216c274f235b4627bb7a2c9f654cb703",
      "0d542d1b446f4cdbb8a36e49001bb243",
      "e368c5ec700146a79a4adde18badc862",
      "4087a6a94a8c403f8b021306551504c4",
      "367529b8575242c0a625bd0df11782ba",
      "f328c294c01c4a09821e4a2bb12291ab",
      "119a391c3ae14c25997d90e3dbc9c89a",
      "3640a0c2a17c4fb08fb6ba992fa3f8c2",
      "c0c9cb1fe9394efa9362fc01df644ec4",
      "0dec9e8511cb498d9b9088f6d109262a",
      "9056521f3a6c421aaf13c030ab528430",
      "f4bd05cae4144ede9086b8f1500a4d29",
      "3602c3a9cfb247d0aadf6c6b981084ed",
      "c74e2ace29e24bc9925fc170cf6e8c9b",
      "4f4f3e8c480b46e98be81aab59144afd",
      "efb940eb21de46f493bcec31a63b2900",
      "189cfd456ce045978f3fba58214b9647",
      "59dbdbbad29c410395e7e09370d0bf62",
      "e9704b85116c439cab8c650536605903",
      "9f14d6329db24efe931053a471dbce7c",
      "7e4bd7986e834bb5bb7d14dbccd7c02f",
      "8858e225b30b414b8c0e7581eb649f65",
      "c40a79af770a4bc489126e24cafacdbb",
      "57c5fa2de5334dbebacd6885673b6d4a",
      "a9d0caac643b48869ea7941de793d8c7",
      "4227b27b88064b1e87b83ec64d3a8d3f",
      "c317463d4d7e4b269ec171bb9bc40541",
      "729be374e786464bb8cfc353cd10e408",
      "f0776727c00843d6a03494edf063e3cd",
      "5cce86793a2d49008cd1892adeae4072",
      "7940bfb8cf224b13928ec490dece9fae"
     ]
    },
    "id": "FpM-IHvBpES7",
    "outputId": "b000b8c5-209f-44ea-fa3b-35bb5dd547bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b0bd172b274a39b291afd1bf5e8fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8b02d1986e4d798d0419db1f1593d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dec9e8511cb498d9b9088f6d109262a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4bd7986e834bb5bb7d14dbccd7c02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True)\n",
    "labeled_data, unlabeled_data, labels, unlabels = balanced_subset(trainset.data, trainset.targets, num_cls=10, num_data=2000)\n",
    "train_images, val_images, train_labels, val_labels = balanced_subset(labeled_data, labels, num_cls=10, num_data=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed9c00-741d-4cf4-addb-e9fbfb7be841",
   "metadata": {
    "id": "Rw9UlfmhpEQK"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.unsqueeze(1)\n",
    "val_images = val_images.unsqueeze(1)\n",
    "trainset = MyDataset(train_images, train_labels, transform=TrainTransform())\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "validationset = MyDataset(val_images, val_labels)\n",
    "valloader = DataLoader(validationset, batch_size=128, shuffle=False)\n",
    "unlabeled_images = unlabeled_data.unsqueeze(1)\n",
    "unlabeledset = MyDataset(unlabeled_images, unlabels)\n",
    "unlabeledloader = DataLoader(unlabeledset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86970b73-d6d0-4997-8877-4a07ae01745d",
   "metadata": {
    "id": "nfgQVvkvpEKC"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "testset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae4ee87-730c-4be9-8975-1fe2b1aae363",
   "metadata": {
    "id": "VIYRgjENpEHn"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.features = nn.Sequential(\n",
    "        nn.Conv2d(1, 64, 3), nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        nn.Conv2d(64, 192, 3, padding=1), nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2))\n",
    "    self.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(192*6*6, 1024), nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(1024, 512), nn.ReLU(),\n",
    "        nn.Linear(512, 10))\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.features(x)\n",
    "    x = x.view(-1, 192*6*6)\n",
    "    x = self.classifier(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd39b6f4-0fda-49b1-bad3-549c6bc1f8ba",
   "metadata": {
    "id": "bTasbMkbpDi4"
   },
   "outputs": [],
   "source": [
    "def accuracy(dataloader):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  with torch.no_grad():\n",
    "    model.eval()\n",
    "    for data in dataloader:\n",
    "      images, labels = data[0].to(device), data[1].to(device)\n",
    "      outputs = model(images)\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "  acc = 100 * correct / total\n",
    "  model.train()\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feffea17-ec72-427a-8d2b-688cab8828d9",
   "metadata": {
    "id": "kgmUMelZ1iBp"
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = \"/content/drive/MyDrive/models/torch_basic_study\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1855d7a7-3878-494b-a009-bcd317704078",
   "metadata": {
    "id": "9YFnFZ341icv"
   },
   "source": [
    "Supervised Learning Model for Pseudo Labaling Model Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e00181-9fe4-491e-9a9c-495786e1085a",
   "metadata": {
    "id": "1zxjalWOpEFQ"
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af59d49-5d8a-4bcd-90f1-f02e56474f04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUnG7GDWvg70",
    "outputId": "2ec29605-16a3-47c1-e4cf-06e7f58e5157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] train acc: 18.50, validation acc: 23.40 - Saved the best model\n",
      "[1] train acc: 40.00, validation acc: 43.80 - Saved the best model\n",
      "[2] train acc: 48.80, validation acc: 55.20 - Saved the best model\n",
      "[10] train acc: 94.20, validation acc: 50.00\n",
      "[11] train acc: 95.40, validation acc: 56.00 - Saved the best model\n",
      "[12] train acc: 95.90, validation acc: 59.50 - Saved the best model\n",
      "[20] train acc: 99.20, validation acc: 59.80 - Saved the best model\n",
      "[27] train acc: 99.50, validation acc: 60.70 - Saved the best model\n",
      "[29] train acc: 99.70, validation acc: 61.30 - Saved the best model\n",
      "[30] train acc: 99.80, validation acc: 56.70\n",
      "[32] train acc: 99.90, validation acc: 62.20 - Saved the best model\n",
      "[40] train acc: 99.80, validation acc: 53.90\n",
      "[41] train acc: 99.80, validation acc: 67.60 - Saved the best model\n",
      "[50] train acc: 98.90, validation acc: 66.20\n",
      "[53] train acc: 99.70, validation acc: 67.90 - Saved the best model\n",
      "[57] train acc: 99.80, validation acc: 72.60 - Saved the best model\n",
      "[60] train acc: 99.80, validation acc: 49.90\n",
      "[61] train acc: 99.80, validation acc: 73.40 - Saved the best model\n",
      "[70] train acc: 100.00, validation acc: 59.80\n",
      "[80] train acc: 99.90, validation acc: 58.40\n",
      "[90] train acc: 100.00, validation acc: 60.90\n",
      "[96] train acc: 100.00, validation acc: 75.80 - Saved the best model\n",
      "[97] train acc: 99.90, validation acc: 78.70 - Saved the best model\n",
      "[100] train acc: 100.00, validation acc: 73.50\n",
      "[110] train acc: 99.30, validation acc: 66.30\n",
      "[120] train acc: 99.50, validation acc: 60.30\n",
      "[124] train acc: 99.30, validation acc: 78.70 - Saved the best model\n",
      "[130] train acc: 100.00, validation acc: 77.40\n",
      "[134] train acc: 99.90, validation acc: 80.90 - Saved the best model\n",
      "[140] train acc: 100.00, validation acc: 78.10\n",
      "[150] train acc: 100.00, validation acc: 67.60\n",
      "[160] train acc: 99.90, validation acc: 68.80\n",
      "[170] train acc: 99.80, validation acc: 67.10\n",
      "[180] train acc: 99.70, validation acc: 76.50\n",
      "[190] train acc: 100.00, validation acc: 69.90\n",
      "[192] train acc: 99.70, validation acc: 84.50 - Saved the best model\n",
      "[200] train acc: 99.80, validation acc: 71.10\n",
      "[210] train acc: 99.60, validation acc: 68.70\n",
      "[220] train acc: 100.00, validation acc: 68.10\n",
      "[230] train acc: 99.80, validation acc: 74.80\n",
      "[240] train acc: 99.80, validation acc: 74.00\n",
      "[250] train acc: 99.80, validation acc: 70.50\n",
      "[260] train acc: 99.90, validation acc: 68.70\n",
      "[270] train acc: 99.40, validation acc: 63.80\n",
      "[275] train acc: 99.30, validation acc: 88.60 - Saved the best model\n",
      "[280] train acc: 99.60, validation acc: 72.70\n",
      "[290] train acc: 99.90, validation acc: 76.60\n",
      "[300] train acc: 99.80, validation acc: 66.20\n",
      "[310] train acc: 99.90, validation acc: 68.10\n",
      "[320] train acc: 99.90, validation acc: 72.30\n",
      "[330] train acc: 100.00, validation acc: 77.90\n",
      "[340] train acc: 99.90, validation acc: 83.30\n",
      "[350] train acc: 100.00, validation acc: 76.00\n",
      "[360] train acc: 100.00, validation acc: 56.60\n",
      "[370] train acc: 100.00, validation acc: 64.40\n",
      "[380] train acc: 100.00, validation acc: 66.70\n",
      "[390] train acc: 100.00, validation acc: 70.80\n",
      "[400] train acc: 99.80, validation acc: 69.50\n",
      "[410] train acc: 99.90, validation acc: 67.30\n",
      "[420] train acc: 100.00, validation acc: 74.30\n",
      "[430] train acc: 99.80, validation acc: 70.50\n",
      "[440] train acc: 99.70, validation acc: 64.20\n",
      "[450] train acc: 99.90, validation acc: 66.80\n",
      "[460] train acc: 99.80, validation acc: 71.30\n",
      "[470] train acc: 100.00, validation acc: 69.50\n",
      "[480] train acc: 100.00, validation acc: 51.70\n",
      "[490] train acc: 100.00, validation acc: 72.50\n",
      "[500] train acc: 99.80, validation acc: 69.40\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "for epoch in range(501):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for traindata in trainloader:\n",
    "    inputs, labels = traindata[0].to(device), traindata[1].to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    _, predicted = torch.max(outputs.detach(), 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "  val_acc = accuracy(valloader)\n",
    "  if val_acc >= best_acc:\n",
    "    best_acc = val_acc\n",
    "    torch.save(model.state_dict(), f\"{MODEL_SAVE_PATH}/cifar_model_for_pseudo_baseline.pt\")\n",
    "    print(\"[%d] train acc: %.2f, validation acc: %.2f - Saved the best model\" %(epoch, 100*correct / total, val_acc))\n",
    "  elif epoch % 10 == 0:\n",
    "    print(\"[%d] train acc: %.2f, validation acc: %.2f\" %(epoch, 100*correct / total, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c72a55-1227-4268-98bd-cb22bd52330b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_YfZRbus1zQJ",
    "outputId": "5e0502ec-c40d-43ce-ef56-1328345c1195"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.95"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"{MODEL_SAVE_PATH}/cifar_model_for_pseudo_baseline.pt\"))\n",
    "accuracy(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecb40af-10ed-4373-8ea0-fc8bc07b73e0",
   "metadata": {
    "id": "iBYnaRCV1vIl"
   },
   "source": [
    "Semi-supervised Learning Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6898d104-9cee-4ef3-a0c9-8c35c5148af1",
   "metadata": {
    "id": "wt9IzeMl6oyR"
   },
   "source": [
    "모델이 일정 수준 학습되면 라벨링이 안된 데이터 또한 예측시키고 나온 예측값과 예측값을 max를 취한 값으로 cost를 계산하여 학습하는 방법."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34adc1b7-51ce-48e8-a2d6-10d5d65f60e9",
   "metadata": {
    "id": "0ynDQTYbvg5d"
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12566034-591c-4b24-9d50-a8e3ad65338b",
   "metadata": {
    "id": "ZRcIqkCUvg25"
   },
   "outputs": [],
   "source": [
    "alpha = 0\n",
    "alpha_t = 1e-4\n",
    "T1 = 100\n",
    "T2 = 450\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f3f9e-ab19-4f6d-995a-e0693a9be867",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tp09z-HDvgym",
    "outputId": "a9046321-a0ff-48f5-a29d-f12cd5fc4112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] train acc: 15.50, validation acc: 26.30 - Saved the best model\n",
      "[1] train acc: 38.90, validation acc: 40.20 - Saved the best model\n",
      "[2] train acc: 48.80, validation acc: 41.60 - Saved the best model\n",
      "[4] train acc: 66.40, validation acc: 55.30 - Saved the best model\n",
      "[7] train acc: 84.90, validation acc: 60.50 - Saved the best model\n",
      "[8] train acc: 89.00, validation acc: 62.30 - Saved the best model\n",
      "[9] train acc: 92.10, validation acc: 66.30 - Saved the best model\n",
      "[10] train acc: 92.80, validation acc: 65.40\n",
      "[12] train acc: 95.00, validation acc: 68.00 - Saved the best model\n",
      "[15] train acc: 98.90, validation acc: 70.80 - Saved the best model\n",
      "[16] train acc: 98.70, validation acc: 70.80 - Saved the best model\n",
      "[19] train acc: 99.20, validation acc: 74.10 - Saved the best model\n",
      "[20] train acc: 99.50, validation acc: 73.60\n",
      "[21] train acc: 99.90, validation acc: 74.30 - Saved the best model\n",
      "[22] train acc: 99.10, validation acc: 81.30 - Saved the best model\n",
      "[30] train acc: 99.70, validation acc: 59.90\n",
      "[40] train acc: 99.80, validation acc: 70.20\n",
      "[50] train acc: 100.00, validation acc: 71.50\n",
      "[60] train acc: 99.50, validation acc: 80.40\n",
      "[65] train acc: 99.50, validation acc: 86.20 - Saved the best model\n",
      "[70] train acc: 99.90, validation acc: 78.80\n",
      "[80] train acc: 99.80, validation acc: 72.40\n",
      "[90] train acc: 98.80, validation acc: 78.20\n",
      "[100] train acc: 99.80, validation acc: 80.10\n",
      "[110] train acc: 100.00, validation acc: 77.50\n",
      "[120] train acc: 100.00, validation acc: 83.60\n",
      "[130] train acc: 99.80, validation acc: 74.90\n",
      "[137] train acc: 99.60, validation acc: 88.30 - Saved the best model\n",
      "[140] train acc: 99.90, validation acc: 83.10\n",
      "[150] train acc: 99.90, validation acc: 80.30\n",
      "[156] train acc: 99.50, validation acc: 91.00 - Saved the best model\n",
      "[160] train acc: 99.80, validation acc: 78.40\n",
      "[170] train acc: 99.90, validation acc: 78.10\n",
      "[180] train acc: 99.30, validation acc: 79.60\n",
      "[190] train acc: 100.00, validation acc: 86.10\n",
      "[200] train acc: 99.70, validation acc: 87.90\n",
      "[210] train acc: 99.90, validation acc: 80.60\n",
      "[220] train acc: 100.00, validation acc: 80.40\n",
      "[230] train acc: 99.90, validation acc: 92.10 - Saved the best model\n",
      "[240] train acc: 100.00, validation acc: 84.90\n",
      "[250] train acc: 99.90, validation acc: 83.00\n",
      "[260] train acc: 100.00, validation acc: 73.20\n",
      "[270] train acc: 100.00, validation acc: 85.90\n",
      "[280] train acc: 99.60, validation acc: 86.80\n",
      "[290] train acc: 99.90, validation acc: 80.10\n",
      "[300] train acc: 99.80, validation acc: 86.60\n",
      "[310] train acc: 99.60, validation acc: 79.40\n",
      "[320] train acc: 99.80, validation acc: 80.90\n",
      "[330] train acc: 99.90, validation acc: 81.80\n",
      "[340] train acc: 100.00, validation acc: 83.30\n",
      "[350] train acc: 99.90, validation acc: 84.70\n",
      "[360] train acc: 100.00, validation acc: 87.30\n",
      "[370] train acc: 100.00, validation acc: 84.00\n",
      "[380] train acc: 99.50, validation acc: 86.90\n",
      "[390] train acc: 99.70, validation acc: 88.00\n",
      "[400] train acc: 99.90, validation acc: 82.50\n",
      "[410] train acc: 99.90, validation acc: 84.50\n",
      "[420] train acc: 100.00, validation acc: 88.10\n",
      "[430] train acc: 99.60, validation acc: 79.30\n",
      "[440] train acc: 99.90, validation acc: 80.80\n",
      "[450] train acc: 100.00, validation acc: 79.20\n",
      "[460] train acc: 100.00, validation acc: 85.30\n",
      "[470] train acc: 99.90, validation acc: 87.40\n",
      "[480] train acc: 99.90, validation acc: 87.40\n",
      "[490] train acc: 99.90, validation acc: 88.50\n",
      "[498] train acc: 100.00, validation acc: 92.40 - Saved the best model\n",
      "[500] train acc: 100.00, validation acc: 83.10\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(501):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for traindata, pseudodata in zip(trainloader, unlabeledloader):\n",
    "    inputs, labels = traindata[0].to(device), traindata[1].to(device)\n",
    "    pinputs = pseudodata[0].to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    if alpha > 0:\n",
    "      poutputs = model(pinputs)\n",
    "      _, plabels = torch.max(poutputs.detach(), 1)\n",
    "      loss = criterion(outputs, labels) + alpha * criterion(poutputs, plabels)\n",
    "    else:\n",
    "      loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    _, predicted = torch.max(outputs.detach(), 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "  if (epoch > T1) and (epoch < T2):\n",
    "    alpha = alpha_t * (epoch - T1) / (T2 - T1)\n",
    "  elif epoch >= T2:\n",
    "    alpha = alpha_t\n",
    "  \n",
    "  val_acc = accuracy(valloader)\n",
    "  if val_acc >= best_acc:\n",
    "    best_acc = val_acc\n",
    "    torch.save(model.state_dict(), f\"{MODEL_SAVE_PATH}/cifar_model_for_pseudo_label1.pt\")\n",
    "    print(\"[%d] train acc: %.2f, validation acc: %.2f - Saved the best model\" %(epoch, 100*correct / total, val_acc))\n",
    "  elif epoch % 10 == 0:\n",
    "    print(\"[%d] train acc: %.2f, validation acc: %.2f\" %(epoch, 100*correct / total, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a88fdfe-c46f-4a75-aaf6-4a19cb1f4ab6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ACBNGxlvg0x",
    "outputId": "4319ce9b-360a-4b25-8c16-5868febcf5ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.08"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"{MODEL_SAVE_PATH}/cifar_model_for_pseudo_label1.pt\"))\n",
    "accuracy(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7d00ea-fc7d-4927-8f51-4f50e4dafec1",
   "metadata": {
    "id": "4ZFJEtKt3VWK"
   },
   "source": [
    "Semi-supervised Learning Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba7c188-33e2-41f3-9f07-d760b9e824f7",
   "metadata": {
    "id": "5f_sSpfu6bHp"
   },
   "source": [
    "라벨링이 된 데이터로 지도 학습된 모델을 이용하여 의사 라벨을 만들어 학습하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee17236b-dad8-47cc-91a0-bdd5db345011",
   "metadata": {
    "id": "j3OSh1Un3YU7"
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load(f\"{MODEL_SAVE_PATH}/cifar_model_for_pseudo_baseline.pt\"))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21daba7c-4fb7-464c-aad4-571e8ddf1bd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gu3lpmIb3ewb",
    "outputId": "1194522d-bbcb-494e-80d1-5317574cba83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:07<00:00, 32.04it/s]\n"
     ]
    }
   ],
   "source": [
    "pseudo_threshold = 0.99\n",
    "pseudo_images = torch.tensor([], dtype=torch.float)\n",
    "pseudo_labels = torch.tensor([], dtype=torch.long)\n",
    "with torch.no_grad():\n",
    "  for data in tqdm(unlabeledloader):\n",
    "    model.eval()\n",
    "    images = data[0].to(device)\n",
    "    outputs = model(images)\n",
    "    outputs = F.softmax(outputs, dim=1)\n",
    "    max_val, predicted = torch.max(outputs.detach(), 1)\n",
    "    idx = np.where(max_val.cpu().numpy() >= pseudo_threshold)[0]\n",
    "    if len(idx) > 0:\n",
    "      pseudo_images = torch.cat((pseudo_images, images.cpu()[idx]), 0)\n",
    "      pseudo_labels = torch.cat((pseudo_labels, predicted.cpu()[idx]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a56812-4118-4bed-9400-691159ef325b",
   "metadata": {
    "id": "wMyMRZBm3etx"
   },
   "outputs": [],
   "source": [
    "pseudo_dataset = MyDataset(pseudo_images, pseudo_labels)\n",
    "pseudoloader = DataLoader(pseudo_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f14ac16-2245-4813-83a7-c3b2545360c0",
   "metadata": {
    "id": "B7WodlsO3YU7"
   },
   "outputs": [],
   "source": [
    "alpha = 0\n",
    "alpha_t = 1e-4\n",
    "T1 = 100\n",
    "T2 = 450\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b705aca7-eba7-4bcb-809f-0b33457fd1a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rIe09b9-3YU7",
    "outputId": "7f002f9a-ae9c-4a45-d798-04b8772155fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] train acc: 100.00, validation acc: 57.90 - Saved the best model\n",
      "[1] train acc: 99.70, validation acc: 76.50 - Saved the best model\n",
      "[10] train acc: 99.90, validation acc: 65.30\n",
      "[13] train acc: 99.80, validation acc: 82.00 - Saved the best model\n",
      "[20] train acc: 99.30, validation acc: 80.10\n",
      "[30] train acc: 99.90, validation acc: 74.50\n",
      "[35] train acc: 99.80, validation acc: 83.80 - Saved the best model\n",
      "[36] train acc: 100.00, validation acc: 84.30 - Saved the best model\n",
      "[40] train acc: 100.00, validation acc: 77.90\n",
      "[50] train acc: 99.50, validation acc: 74.70\n",
      "[60] train acc: 99.90, validation acc: 80.20\n",
      "[70] train acc: 99.60, validation acc: 75.60\n",
      "[80] train acc: 100.00, validation acc: 67.60\n",
      "[90] train acc: 100.00, validation acc: 71.50\n",
      "[100] train acc: 100.00, validation acc: 78.40\n",
      "[103] train acc: 100.00, validation acc: 84.50 - Saved the best model\n",
      "[104] train acc: 100.00, validation acc: 88.80 - Saved the best model\n",
      "[110] train acc: 100.00, validation acc: 86.50\n",
      "[120] train acc: 100.00, validation acc: 39.30\n",
      "[130] train acc: 100.00, validation acc: 21.90\n",
      "[140] train acc: 99.90, validation acc: 25.20\n",
      "[150] train acc: 100.00, validation acc: 23.60\n",
      "[160] train acc: 99.40, validation acc: 14.40\n",
      "[170] train acc: 99.70, validation acc: 14.40\n",
      "[180] train acc: 99.80, validation acc: 24.80\n",
      "[190] train acc: 99.80, validation acc: 12.20\n",
      "[200] train acc: 99.80, validation acc: 20.30\n",
      "[210] train acc: 99.90, validation acc: 22.20\n",
      "[220] train acc: 100.00, validation acc: 19.60\n",
      "[230] train acc: 100.00, validation acc: 25.30\n",
      "[240] train acc: 100.00, validation acc: 24.00\n",
      "[250] train acc: 99.90, validation acc: 30.90\n",
      "[260] train acc: 100.00, validation acc: 24.40\n",
      "[270] train acc: 100.00, validation acc: 26.20\n",
      "[280] train acc: 99.90, validation acc: 29.40\n",
      "[290] train acc: 99.90, validation acc: 32.50\n",
      "[300] train acc: 99.70, validation acc: 23.90\n",
      "[310] train acc: 100.00, validation acc: 34.70\n",
      "[320] train acc: 100.00, validation acc: 32.20\n",
      "[330] train acc: 99.90, validation acc: 32.00\n",
      "[340] train acc: 100.00, validation acc: 32.30\n",
      "[350] train acc: 100.00, validation acc: 41.60\n",
      "[360] train acc: 100.00, validation acc: 37.10\n",
      "[370] train acc: 100.00, validation acc: 38.90\n",
      "[380] train acc: 100.00, validation acc: 46.10\n",
      "[390] train acc: 100.00, validation acc: 42.60\n",
      "[400] train acc: 100.00, validation acc: 48.40\n",
      "[410] train acc: 100.00, validation acc: 50.70\n",
      "[420] train acc: 99.90, validation acc: 54.00\n",
      "[430] train acc: 100.00, validation acc: 38.00\n",
      "[440] train acc: 99.80, validation acc: 58.20\n",
      "[450] train acc: 99.90, validation acc: 46.30\n",
      "[460] train acc: 99.90, validation acc: 33.70\n",
      "[470] train acc: 100.00, validation acc: 45.90\n",
      "[480] train acc: 100.00, validation acc: 56.80\n",
      "[490] train acc: 99.80, validation acc: 54.50\n",
      "[500] train acc: 100.00, validation acc: 54.60\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(501):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for traindata, pseudodata in zip(trainloader, pseudoloader):\n",
    "    inputs, labels = traindata[0].to(device), traindata[1].to(device)\n",
    "    pinputs, plabels = pseudodata[0].to(device), pseudodata[1].to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    poutputs = model(pinputs)\n",
    "    loss = criterion(outputs, labels) + alpha * criterion(poutputs, plabels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    _, predicted = torch.max(outputs.detach(), 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "  if (epoch > T1) and (epoch < T2):\n",
    "    alpha = alpha_t * (epoch - T1) / (T2 - T1)\n",
    "  elif epoch >= T2:\n",
    "    alpha = alpha_t\n",
    "  \n",
    "  val_acc = accuracy(valloader)\n",
    "  if val_acc >= best_acc:\n",
    "    best_acc = val_acc\n",
    "    torch.save(model.state_dict(), f\"{MODEL_SAVE_PATH}/cifar_model_for_pseudo_label2.pt\")\n",
    "    print(\"[%d] train acc: %.2f, validation acc: %.2f - Saved the best model\" %(epoch, 100*correct / total, val_acc))\n",
    "  elif epoch % 10 == 0:\n",
    "    print(\"[%d] train acc: %.2f, validation acc: %.2f\" %(epoch, 100*correct / total, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ae5cd9-491c-4978-be47-b96d00f4e8c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xg4U3y1c3YU7",
    "outputId": "eab0fb3b-fb21-4ea3-b714-ce6f7c96234f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"{MODEL_SAVE_PATH}/cifar_model_for_pseudo_label2.pt\"))\n",
    "accuracy(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1489cb-13ff-4824-8866-c8c02dda1da0",
   "metadata": {
    "id": "HXcMwSH_jeyI"
   },
   "source": [
    "결과적으로 1번 준지도 학습 방법이 성능을 향상시켰다. 2번 준지도 학습의 경우 부정확한 라벨링으로 때문에 성능 저하가 발생한듯 하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
